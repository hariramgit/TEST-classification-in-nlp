{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/labsuser/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/labsuser/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/labsuser/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bbc-text.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAPE OF DATASET: \n",
      "(2225, 2)\n",
      "Index(['category', 'text'], dtype='object')\n",
      "['tech' 'business' 'sport' 'entertainment' 'politics']\n"
     ]
    }
   ],
   "source": [
    "# Description of the dataset\n",
    "print('SHAPE OF DATASET: ')\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF SAMPLES IN EACH CATEGORY: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='category', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plotting number of samples within each category\n",
    "print('NUMBER OF SAMPLES IN EACH CATEGORY: \\n')\n",
    "sns.countplot(df.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning in progress...\n",
      "Tokenization complete.\n"
     ]
    }
   ],
   "source": [
    "# DATA CLEANING\n",
    "print('Data cleaning in progress...')\n",
    "\n",
    "# Tokenize\n",
    "df['text_clean'] = df['text'].apply(nltk.word_tokenize)\n",
    "print('Tokenization complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words removed.\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words\n",
    "stop_words=set(nltk.corpus.stopwords.words(\"english\"))\n",
    "df['text_clean'] = df['text_clean'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "print('Stop words removed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers, punctuation and special characters removed.\n"
     ]
    }
   ],
   "source": [
    "# Remove numbers, punctuation and special characters (only keep words)\n",
    "regex = '[a-z]+'\n",
    "df['text_clean'] = df['text_clean'].apply(lambda x: [item for item in x if re.match(regex, item)])\n",
    "print('Numbers, punctuation and special characters removed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization complete.\n",
      "Data cleaning complete.\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization\n",
    "lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "df['text_clean'] = df['text_clean'].apply(lambda x: [lem.lemmatize(item, pos='v') for item in x])\n",
    "print('Lemmatization complete.\\nData cleaning complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes :\n",
      "Accuracy: 0.366 \tPrecision: 0.379 \tRecall: 0.344 \t\tF1: 0.339\n",
      "\n",
      "SVC :\n",
      "Accuracy: 0.326 \tPrecision: 0.134 \tRecall: 0.277 \t\tF1: 0.179\n",
      "\n",
      "Decision Tree :\n",
      "Accuracy: 0.335 \tPrecision: 0.340 \tRecall: 0.332 \t\tF1: 0.334\n",
      "\n",
      "Perceptron :\n",
      "Accuracy: 0.326 \tPrecision: 0.136 \tRecall: 0.279 \t\tF1: 0.179\n",
      "\n",
      "Gradient Boosting :\n",
      "Accuracy: 0.420 \tPrecision: 0.407 \tRecall: 0.411 \t\tF1: 0.405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Classification using word2vec vectorizer\n",
    "\n",
    "vec_model = Word2Vec(df['text_clean'])\n",
    "w2v = dict(zip(vec_model.wv.index2word, vec_model.wv.syn0))\n",
    "\n",
    "class Vectorizer(object):\n",
    "    \n",
    "    def __init__(self, vec):\n",
    "        self.vec = vec\n",
    "        self.dim = len(vec.values())\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([np.mean([self.vec[w] for w in words if w in self.vec] or [np.zeros(self.dim)], axis=0) for words in X])\n",
    "\n",
    "class Classifier(object):\n",
    "    \n",
    "    def __init__(self, model, param):\n",
    "        self.model = model\n",
    "        self.param = param\n",
    "        self.gs = GridSearchCV(self.model, self.param, cv=5, error_score=0, refit=True)        \n",
    "\n",
    "    def fit(self, X, y):        \n",
    "        return self.gs.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.gs.predict(X)\n",
    "\n",
    "clf_models = {\n",
    "    'Naive Bayes': GaussianNB(), \n",
    "    'SVC': SVC(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),  \n",
    "    'Perceptron': MLPClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "clf_params = {\n",
    "    'Naive Bayes': { }, \n",
    "    'SVC': { 'kernel': ['linear', 'rbf'] },\n",
    "    'Decision Tree': { 'min_samples_split': [2, 5] }, \n",
    "    'Perceptron': { 'activation': ['tanh', 'relu'] },\n",
    "    'Gradient Boosting': { 'min_samples_split': [2, 5] }\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.2, shuffle=True)\n",
    "\n",
    "for key in clf_models.keys():\n",
    "    \n",
    "    clf = Pipeline([('Word2Vec vectorizer', Vectorizer(w2v)), ('Classifier', Classifier(clf_models[key], clf_params[key]))])\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(key, ':')\n",
    "    print(\"Accuracy: %1.3f \\tPrecision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (accuracy_score(y_test, y_pred), precision_score(y_test, y_pred, average='macro'), recall_score(y_test, y_pred, average='macro'), f1_score(y_test, y_pred, average='macro')))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization complete.\n",
      "\n",
      "Naive Bayes : {'alpha': 0.5, 'fit_prior': False}\n",
      "Precision: 0.962 \tRecall: 0.960 \t\tF1: 0.960\n",
      "\n",
      "Decision Tree : {'min_samples_split': 2}\n",
      "Precision: 0.797 \tRecall: 0.789 \t\tF1: 0.792\n",
      "\n",
      "Perceptron : {'activation': 'tanh', 'alpha': 0.001}\n",
      "Precision: 0.976 \tRecall: 0.975 \t\tF1: 0.975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification using TFIDF vectorizer\n",
    "\n",
    "# Vectorize training and testing data\n",
    "def Vectorize(vec, X_train, X_test):    \n",
    "    \n",
    "    X_train_vec = vec.fit_transform(X_train)\n",
    "    X_test_vec = vec.transform(X_test)\n",
    "    \n",
    "    print('Vectorization complete.\\n')\n",
    "    \n",
    "    return X_train_vec, X_test_vec\n",
    "\n",
    "# Use multiple classifiers and grid search for prediction\n",
    "def ML_modeling(models, params, X_train, X_test, y_train, y_test):    \n",
    "    \n",
    "    if not set(models.keys()).issubset(set(params.keys())):\n",
    "        raise ValueError('Some estimators are missing parameters')\n",
    "\n",
    "    for key in models.keys():\n",
    "    \n",
    "        model = models[key]\n",
    "        param = params[key]\n",
    "        gs = GridSearchCV(model, param, cv=5, error_score=0, refit=True)\n",
    "        gs.fit(X_train, y_train)\n",
    "        y_pred = gs.predict(X_test)\n",
    "        \n",
    "        # Print scores for the classifier\n",
    "        print(key, ':', gs.best_params_)\n",
    "        print(\"Precision: %1.3f \\tRecall: %1.3f \\t\\tF1: %1.3f\\n\" % (precision_score(y_test, y_pred, average='macro'), recall_score(y_test, y_pred, average='macro'), f1_score(y_test, y_pred, average='macro')))\n",
    "    \n",
    "    return\n",
    "\n",
    "models = {\n",
    "    'Naive Bayes': MultinomialNB(), \n",
    "    'Decision Tree': DecisionTreeClassifier(),  \n",
    "    'Perceptron': MLPClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'Naive Bayes': { 'alpha': [0.5, 1], 'fit_prior': [True, False] }, \n",
    "    'Decision Tree': { 'min_samples_split': [1, 2, 5] }, \n",
    "    'Perceptron': { 'alpha': [0.0001, 0.001], 'activation': ['tanh', 'relu'] },\n",
    "    'Gradient Boosting': { 'learning_rate': [0.05, 0.1], 'min_samples_split': [2, 5] }\n",
    "}\n",
    "\n",
    "# Encode label categories to numbers\n",
    "enc = LabelEncoder()\n",
    "df['category'] = enc.fit_transform(df['category'])\n",
    "labels = list(enc.classes_)\n",
    "\n",
    "# Train-test split and vectorize\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['category'], test_size=0.2, shuffle=True)\n",
    "X_train_vec, X_test_vec = Vectorize(TfidfVectorizer(), X_train, X_test)\n",
    "\n",
    "ML_modeling(models, params, X_train_vec, X_test_vec, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
